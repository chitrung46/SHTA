[data]
num_nodes = 170
lag = 12
horizon = 12
normalizer = std
val_ratio = 0.2
test_ratio = 0.2
tod = False
column_wise = False
default_graph = True

[model]
in_dim = 1
out_dim = 1
channels = 16
dynamic = True
dropout = 0.0001
memory_size = 16
embed_dim = 16
embed_dim_spa = 4
hidden_dim = 64

[train]
batch_size = 64
epochs = 10
lr_init = 0.003
lr_decay = True
lr_decay_rate = 0.3
lr_decay_step = 25, 50, 75
early_stop = True
early_stop_patience = 20
grad_norm = True
max_grad_norm = 5
debug = False
real_value = False
seed_mode = True
seed = 12
xavier = False
loss_func = mask_mae
load_pretrain_path = /GPTST_ada.pth
save_pretrain_path = new_pretrain_model.pth
change_epoch = 10
up_epoch = 110, 170, 250

[test]
mae_thresh = 0.
mape_thresh = 0.

[log]
log_step = 20
plot = False